{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyimagesearch.centroidtracker import CentroidTracker\r\n",
    "from pyimagesearch.trackableobject import TrackableObject\r\n",
    "from numpy.lib.utils import info\r\n",
    "from imutils.video import VideoStream\r\n",
    "from imutils.video import FPS\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import imutils\r\n",
    "import numpy as np\r\n",
    "import argparse\r\n",
    "import time\r\n",
    "import dlib\r\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\r\n",
    "    \"prototxt\": \"mobilenet_ssd/MobileNetSSD_deploy.prototxt\",\r\n",
    "    \"model\": \"mobilenet_ssd/MobileNetSSD_deploy.caffemodel\",\r\n",
    "    \"input\": \"videos/example_01.mp4\", #video for testing\r\n",
    "    \"output\": \"videos/output.mp4\", #path for video after running the model\r\n",
    "    \"confidence\": 0.4,\r\n",
    "    \"skip_frames\": 30\r\n",
    " } #parsing the arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening video file...\n"
     ]
    }
   ],
   "source": [
    "#MOBILENET SSD\n",
    "#initializing the classes for mobilenet\n",
    "CLASSSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\"dog\", \"horse\", \"mototbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\",\n",
    "\"train\", \"tvmonitor\"]\n",
    "\n",
    "#initializing mobilenet\n",
    "net = cv2.dnn.readNetFromCaffe(args[\"prototxt\"], args[\"model\"])\n",
    "\n",
    "#testing the model with or video or initializing the webcam if none is supplied\n",
    "if not args.get(\"input\", False):\n",
    "    print(\"initializing video stream\")\n",
    "    vs = VideoStream(src=0).start()\n",
    "    time.sleep(2.0)\n",
    "\n",
    "else:\n",
    "    print(\"opening video file...\")\n",
    "    vs = cv2.VideoCapture(args[\"input\"])\n",
    "\n",
    "#video writer\n",
    "writer = None\n",
    "\n",
    "#frame dimensions\n",
    "W, H = None, None\n",
    "\n",
    "#instatiating a centroid tracker, a list and dictionary for storing each correlation\n",
    "#and a dictionary to map each object ID to a unique object\n",
    "ct = CentroidTracker(maxDisappeared=40, maxDistance=50)\n",
    "trackers = []\n",
    "trackableObjects = {}\n",
    "\n",
    "#intializing processed frames and number of objects that have moved up or down\n",
    "totalFrames = 0\n",
    "totalDown = 0\n",
    "totalUp = 0\n",
    "\n",
    "#frames per second throughput estimator for benchmarking\n",
    "fps = FPS().start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "while True:\r\n",
    "    #grab the next frame and handle\r\n",
    "    frame= vs.read()\r\n",
    "    frame = frame[1] if args.get(\"input\", False) else frame\r\n",
    "    #video is ended if no frame is grabbed\r\n",
    "    if args[\"input\"] is not None and frame is None:\r\n",
    "        break\r\n",
    "\r\n",
    "    frame = imutils.resize(frame, width=500)\r\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\r\n",
    "\r\n",
    "    #set the frame if they are empty\r\n",
    "    if W is None or H is None:\r\n",
    "        (H, W) = frame.shape[:2]\r\n",
    "\r\n",
    "    #writer is intitialized if video is written to a disk\r\n",
    "    if args[\"output\"] is not None and writer is None:\r\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\r\n",
    "\r\n",
    "        writer = cv2.VideoWriter(args[\"output\"], fourcc, 30 ,(W, H), True)\r\n",
    "\r\n",
    "\r\n",
    "    status = \"Waiting\"\r\n",
    "    rects = []\r\n",
    "\r\n",
    "    if totalFrames % args[\"skip_frames\"] == 0:\r\n",
    "        status = \"Detecting\"\r\n",
    "        trackers = []\r\n",
    "\r\n",
    "        #performing inferences\r\n",
    "        blob = cv2.dnn.blobFromImage(frame, 0.007843, (W, H), 127.5)\r\n",
    "        net.setInput(blob)\r\n",
    "        detections = net.forward()\r\n",
    "\r\n",
    "        #looping over the detections\r\n",
    "        for i in np.arange(0, detections.shape[2]):\r\n",
    "            #extracting the probability for each prediction\r\n",
    "            confidence = detections[0, 0, i, 2]\r\n",
    "\r\n",
    "            #filtering weak predictions\r\n",
    "            if confidence > args[\"confidence\"]:\r\n",
    "                index = int(detections[0, 0, i, 1])\r\n",
    "\r\n",
    "                #ignoring the class if it is not person\r\n",
    "                if CLASSSES[index] != \"person\":\r\n",
    "                    continue\r\n",
    "\r\n",
    "                #computing the bounding box cooordinates\r\n",
    "                box = detections[0, 0, i, 3:7] * np.array([W, H, W, H])\r\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\r\n",
    "\r\n",
    "                #constructing a rectangle from the biunding box\r\n",
    "                tracker = dlib.correlation_tracker()\r\n",
    "                rect = dlib.rectangle(startX, startY, endX, endY)\r\n",
    "                tracker.start_track(rgb, rect)\r\n",
    "\r\n",
    "                #add tracker to the list of trackers\r\n",
    "                trackers.append(tracker)\r\n",
    "    #utilizing trackers rather than detectors for higher frame processing throughput\r\n",
    "    else:\r\n",
    "        #looping over the trackers\r\n",
    "        for tracker in trackers:\r\n",
    "            status = \"Tracking\"\r\n",
    "\r\n",
    "            #updating the tracker and position\r\n",
    "            tracker.update(rgb)\r\n",
    "            pos = tracker.get_position()\r\n",
    "\r\n",
    "            startX = int(pos.left())\r\n",
    "            startY = int(pos.top())\r\n",
    "            endX = int(pos.right())\r\n",
    "            endY = int(pos.bottom())\r\n",
    "\r\n",
    "            #adding the bounding box coordintes \r\n",
    "            rects.append((startX, startY, endX, endY))\r\n",
    "    #draawing the horizontal line        \r\n",
    "    cv2.line(frame, (0, H // 2), (W, H //2), (0, 255, 255), 2)\r\n",
    "\r\n",
    "    #using the centroid tracker to update old centroid swith the newly computed ones\r\n",
    "    objects = ct.update(rects)\r\n",
    "\r\n",
    "    #looping over tracked objects\r\n",
    "    for (objectID, centroid) in objects.items():\r\n",
    "\r\n",
    "        #check if a trckable object exists for the current one\r\n",
    "        to = trackableObjects.get(objectID, None)\r\n",
    "        if to is None:\r\n",
    "            to = TrackableObject(objectID, centroid)\r\n",
    "        \r\n",
    "        #create one if none exists\r\n",
    "        else:\r\n",
    "            y = [c[1] for c in to.centroids]\r\n",
    "            #direction is determined by the difference between current and previous y coordinates\r\n",
    "            direction = centroid[1] - np.mean(y)\r\n",
    "            to.centroids.append(centroid)\r\n",
    "            if not to.counted:\r\n",
    "                if direction < 0 and centroid[1] < H // 2:\r\n",
    "                    totalUp +=1\r\n",
    "                    to.counted = True\r\n",
    "\r\n",
    "                elif direction > 0 and centroid[1] > H // 2:\r\n",
    "                    totalDown +=1\r\n",
    "                    to.counted = True\r\n",
    "        \r\n",
    "        #storing the trackable object\r\n",
    "        trackableObjects[objectID] = to\r\n",
    "\r\n",
    "        #writing the object ID\r\n",
    "        text = \"ID {}\".format(objectID)\r\n",
    "        cv2.putText(frame, text, (centroid[0] - 10, centroid[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\r\n",
    "        cv2.circle(frame, (centroid[0], centroid[1]), 4, (0,255,0), -1)\r\n",
    "\r\n",
    "    #tulpe of info on the screen\r\n",
    "    info  = [\r\n",
    "        (\"up\", totalUp),\r\n",
    "        (\"down\", totalDown),\r\n",
    "        (\"status\", status),\r\n",
    "    ]\r\n",
    "\r\n",
    "    #drawing our frame\r\n",
    "    for (i, (k,v)) in enumerate(info):\r\n",
    "        text = \"{}: {}\".format(k, v)\r\n",
    "        cv2.putText(frame, text, (10, H - ((i * 20) + 20)), cv2.FONT_HERSHEY_SIMPLEX, 0.6,  (0, 0, 255), 2)\r\n",
    "\r\n",
    "    #writing the frame if necessary\r\n",
    "    if writer is not None:\r\n",
    "        writer.write(frame)\r\n",
    "\r\n",
    "    #displaying the frame\r\n",
    "    cv2.imshow(\"Frame\", frame)\r\n",
    "    key = cv2.waitKey(1) & 0xFF\r\n",
    "\r\n",
    "    if key == ord(\"q\"):\r\n",
    "        break\r\n",
    "    totalFrames +=1\r\n",
    "\r\n",
    "    #updating the frames per second info\r\n",
    "    fps.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time 35.77\n",
      "approx. FPS 35.87\n",
      "3\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "fps.stop()\n",
    "print(\"elapsed time {:.2f}\".format(fps.elapsed()))\n",
    "print(\"approx. FPS {:.2f}\".format(fps.fps()))\n",
    "print(totalUp)\n",
    "print(totalDown)\n",
    "if writer is not None:\n",
    "    writer.release()\n",
    "\n",
    "if not args.get(\"input\", False):\n",
    "    vs.stop()\n",
    "else:\n",
    "    vs.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7c7f5672e95a9a2be42c4e43928e5e599e28d6d26d9dcfa3497d9cc4975c9c7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}